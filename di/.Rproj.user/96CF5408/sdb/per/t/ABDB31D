{
    "collab_server" : "",
    "contents" : "#' This subroutine calculates the volume of a d-dimensional unit ball for Euclidean norm\n#'\n#' @param d number of deminsion\n#' @return a numeric value for the d-dimensional unit ball for Euclidean norm\n#' @export\nvd <- function(d){\n\t0.5 * d * log(pi) - log(gamma(0.5 * d + 1))\n}\n\n#' This function estimates the entropy of a continuous random variable\n#'\n#' @param x data matrix used for calculating the entropy\n#' @param k number for nearest neighbors used in entropy calculation\n#' @importFrom RANN nn2\n#' @return a vector of entropy values\n#' @export\nentropy <- function(x, k = 5) {\n  if(is.numeric(x))\n    x <- as.matrix(x)\n \tN <- nrow(x) # The number of observed samples\n \td <- ncol(x) # The number of the dimensions of the data\n\n \tknn_dis <- RANN::nn2(x, k = k + 1)$nn.dists[, k + 1]\n \tans <- -digamma(k) + digamma(N)\n\n \treturn(ans + d * mean(log(knn_dis)))\n}\n\n#' This function estimates the mutual information of two random variables based on their observed values\n#'\n#' @param x one random variable from the time-series data\n#' @param y another random variable from the time-series data\n#' @param k number for nearest neighbors used in entropy calculation\n#' @importFrom RANN nn2\n#' @return a numeric value for the mutual information estimator between two variables (x, y)\n#' @export\nmi <- function(x, y, k = 5) {\n  if(is.numeric(x))\n    x <- as.matrix(x)\n  if(is.numeric(y))\n      y <- as.matrix(y)\n\n  N <- nrow(x)\n\tif(nrow(y) != N)\n\t\twarning('Matrix should have the same length')\n\tdx <- ncol(x)\n\tdy <- ncol(y)\n\tdata <- cbind(x, y)\n\n\tx_knn_res <- RANN::nn2(x, k = nrow(x))\n\ty_knn_res <- RANN::nn2(y, k = nrow(y))\n\tdata_knn_res <- RANN::nn2(data, k = nrow(x))\n\n\tknn_dis <- data_knn_res$nn.dists[, k + 1]\n\tinformation_samples <- rep(digamma(N), N)\n\n\tRANN::nn2(data, radius = knn_dis[1])$nn.idx\n\t#run the nn2 only once for all data in a vector\n\tfor(i in 1:N){\n\t  # print(c(sum(data_knn_res$nn.dists[i, ] <= knn_dis[i]), sum(x_knn_res$nn.dists[i, ] <= knn_dis[i]), sum(y_knn_res$nn.dists[i, ] <= knn_dis[i])))\n\t  information_samples[i] <- information_samples[i] + digamma(sum(data_knn_res$nn.dists[i, ] <= knn_dis[i]) - 1) #always k\n\t  information_samples[i] <- information_samples[i] - digamma(sum(x_knn_res$nn.dists[i, ] <= knn_dis[i]) - 1)\n\t  information_samples[i] <- information_samples[i] - digamma(sum(y_knn_res$nn.dists[i, ] <= knn_dis[i]) - 1)\n\t}\n\n   return(mean(information_samples))\n}\n\n#' This function estimates the CONDITIONAL mutual information of X and Y given Z\n#'\n#' @param x one random variable from the time-series data\n#' @param y another random variable from the time-series data\n#' @param z condition random variable for variables (x, y) from the time-series data\n#' @param k number for nearest neighbors used in entropy calculation\n#' @importFrom RANN nn2\n#' @return a numeric value for the condition mutual information estimator between two variables (x, y) conditioned on variable z\n#' @export\ncmi <- function(x, y, z, k=5) {\n  if(is.numeric(x))\n    x <- as.matrix(x)\n  if(is.numeric(y))\n    y <- as.matrix(y)\n  if(is.numeric(z))\n    z <- as.matrix(z)\n\n  N <- nrow(x)\n\tif(nrow(y) != N | nrow(z) != N)\n\t\twarning('Matrix should have the same length')\n\n\tdx <- ncol(x)\n\tdy <- ncol(y)\n\tdz <- ncol(z)\n\n\tdata_xyz <- Reduce(cbind, list(x, y, z))\n\tdata_xz <- cbind(x, z)\n\tdata_yz <- cbind(y, z)\n\n\txz_knn_res <- RANN::nn2(data_xz, k = nrow(data_xz))\n\tyz_knn_res <- RANN::nn2(data_yz, k = nrow(data_yz))\n\tz_res <- RANN::nn2(z, k = nrow(z))\n\tdata_knn_res <- RANN::nn2(data_xyz, k = nrow(data_yz))\n\n\tknn_dis <- data_knn_res$nn.dists[, k + 1]\n\tinformation_samples <- rep(0, N)\n\n\t#run the nn2 only once for all data in a vector\n\tfor(i in 1:N){\n\t  # print(c(sum(data_knn_res$nn.dists[i, ] <= knn_dis[i]), sum(xz_knn_res$nn.dists[i, ] <= knn_dis[i]), sum(yz_knn_res$nn.dists[i, ] <= knn_dis[i]), sum(z_res$nn.dists[i, ] <= knn_dis[i])))\n\t  # print(c(digamma(sum(data_knn_res$nn.dists[i, ] <= knn_dis[i]) - 1), digamma(sum(xz_knn_res$nn.dists[i, ] <= knn_dis[i]) - 1), digamma(sum(yz_knn_res$nn.dists[i, ] <= knn_dis[i]) - 1), digamma(sum(z_res$nn.dists[i, ] <= knn_dis[i]) - 1)))\n\n\t  information_samples[i] <- information_samples[i] + digamma(sum(data_knn_res$nn.dists[i, ] <= knn_dis[i]) - 1)\n\t  information_samples[i] <- information_samples[i] - digamma(sum(xz_knn_res$nn.dists[i, ] <= knn_dis[i]) - 1)\n\t  information_samples[i] <- information_samples[i] - digamma(sum(yz_knn_res$nn.dists[i, ] <= knn_dis[i]) - 1)\n\t  information_samples[i] <- information_samples[i] + digamma(sum(z_res$nn.dists[i, ] <= knn_dis[i]) - 1)\n\t}\n\n\t# print(information_samples)\n  return(mean(information_samples))\n}\n\n#' This function simulates the DIRECTED mutual information from X to Y when you have a SINGLE run of the process\n#'\n#' @param x one random variable from the time-series data\n#' @param y another random variable from the time-series data\n#' @param d delay in the formula I(x-->y)=I(x_{t-d};y_t|y_{t-1}) default: d=1\n#' @return a matrix for the condition mutual information estimators between all pairwise variables (x, y) in the data matrix x, y\n#' @export\ndi_single_run <- function(x, y, n=10) {\n  if(is.numeric(x))\n    x <- as.matrix(x)\n  if(is.numeric(y))\n    y <- as.matrix(y)\n\n  if(ncol(x) != ncol(y))\n \t\tstop('The number of time samples has to be the same for X and Y')\n    tau <- n\n    tot_len <- nrow(x) - tau\n    x_past <- x[(tau):(tau - 1 + tot_len), ]\n    y_past <- y[(tau):(tau - 1 + tot_len), ]\n    for(i in 2:n) {\n        x_past = cbind(x[(tau - i + 1):(tau - i + tot_len), ], x_past)\n        y_past = cbind(y[(tau - i + 1):(tau - i + tot_len), ], y_past)\n    }\n\n    return(cmi(x_past, as.matrix(y[(tau + 1):(tau+tot_len), ]), y_past))\n}\n\n#' This function simulates the CONDITIONED DIRECTED mutual information from X to Y when you have a SINGLE run of the processes\n#'\n#' @param x one random variable from the time-series data\n#' @param y another random variable from the time-series data\n#' @param z z is a dataframe (or matrix) containing the data of other processes upon the past of which the mi is conditioned\n#' @param n Parameter n determines the the number of previous time samples upon which the mi is conditioned\n#' @return a matrix for the condition mutual information estimators between all pairwise variables (x, y) in the data matrix x, y\n#' @export\ndi_single_run_conditioned <- function(x, y, z, n = 10) {\n  if(is.numeric(x))\n    x <- as.matrix(x)\n  if(is.numeric(y))\n    y <- as.matrix(y)\n  if(is.numeric(z))\n    z <- as.matrix(z)\n\n  if(ncol(x) != ncol(y))\n \t\tstop('The number of time samples has to be the same for X and Y')\n \tif(nrow(x) != nrow(z))\n \t\tstop('The number of time samples has to be the same for X and all Zs')\n\n    tau <- n\n    tot_len <- nrow(x) - tau\n    x_past <- x[(tau):(tau - 1 + tot_len), ]\n    yz_past <- y[(tau):(tau - 1 + tot_len), ]\n    for(i in 1:n){\n\t\tif(i > 1) {\n\t        x_past <- cbind(x[(tau - i + 1):(tau - i + tot_len), ], x_past)\n\t        yz_past <- cbind(y[(tau - i + 1):(tau - i + tot_len), ], yz_past)\n        }\n      \tfor(j in 1:ncol(z)){\n      \t\tyz_past <- cbind(z[(tau - i + 1):(tau - i + tot_len), j], yz_past)\n      \t}\n    }\n\n    return(cmi(x_past, y[(tau + 1):(tau+tot_len), ], yz_past))\n}\n\n#' This function simulates the RESTRICTED DIRECTED mutual information from X to Y when you have a SINGLE run of the processes\n#'\n#' @param x one random variable from the time-series data\n#' @param y another random variable from the time-series data\n#' @param d delay in the formula I(x-->y)=I(x_{t-d};y_t|y_{t-1}) default: d=1\n#' @return a matrix for the condition mutual information estimators between all pairwise variables (x, y) in the data matrix x, y\n#' @export\nrdi_single_run <- function(x, y, d=1) {\n  if(is.numeric(x))\n    x <- as.matrix(x)\n  if(is.numeric(y))\n    y <- as.matrix(y)\n\n  if(nrow(x) != nrow(y))\n \t\tstop('The number of time samples has to be the same for X and Y')\n\n    return(cmi(x[1:(nrow(x) - d), ], y[-(1:d), ], y[d:(nrow(y) - 1), ]))\n}\n\n#' This function simulates the CONDITIONED DIRECTED mutual information from X to Y CONDITIONED ON Z when you have a SINGLE run of the processes\n#'\n#' @param x one random variable from the time-series data\n#' @param y another random variable from the time-series data\n#' @param z z is a dataframe or matrix consisting of the data for different variables\n#' @param z_delay z_delay is also a dataframe or matrix consisting of the delays to be applied to different variables\n#' @param d delay in the formula I(x-->y)=I(x_{t-d};y_t|y_{t-1}) default: d=1\n#' @return a matrix for the condition mutual information estimators between all pairwise variables (x, y) in the data matrix x, y\n#' @export\nrdi_single_run_conditioned <- function(x, y, z, z_delays, d = 1) {\n  if(is.numeric(x))\n    x <- as.matrix(x)\n  if(is.numeric(y))\n    y <- as.matrix(y)\n  if(is.numeric(z))\n    z <- as.matrix(z)\n\n  if(nrow(x) != nrow(y))\n \t\tstop('The number of time samples has to be the same for X and Y')\n \tif(nrow(x) != nrow(z))\n \t\tstop('The number of time samples has to be the same for X and all Zs')\n\n    tau <- max(c(z_delays, d))\n    tot_len <- nrow(x) - tau\n    yz <- y[(tau):(tau - 1 + tot_len), ]\n    for(i in 1:ncol(z)){\n        # yz = np.concatenate( (z[key][tau-z_delays[key]:tau-z_delays[key]+tot_len], yz), axis=1)\n        yz <- cbind(z[(tau - z_delays[i] + 1):(tau-z_delays[i]+tot_len), i], yz)\n    }\n\n    return(cmi(x[(tau - d + 1):(tau - d + tot_len), ], y[(tau + 1):(tau + tot_len), ], yz))\n}\n\n#' other functions need to implement:\n#' sc (Shannon capacity);\n#' csc (Conditioned Shannon capacity);\n#' causal_sc (Causal Shannon capacity);\n#' causal_sc_conditioned\n#' d_regularizer\n#' get_obj\n#' get_grad\n#' projection\n\n\n#' #' This function simulates the DIRECTED mutual information from X to Y when you have MANY runs of the processes\n#' #'\n#' #' @param x one random variable from the time-series data\n#' #' @param y another random variable from the time-series data\n#' #' @return a matrix for the condition mutual information estimators between all pairwise variables (x, y) in the data matrix x, y\n#' #' @export\n#' # rdi_many_runs <- function(x, y) {\n#' #  \tif(ncol(x) != ncol(y))\n#' #  \t\tstop('The number of time samples has to be the same for X and Y')\n#'\n#' #     T <- ncol(x)\n#' #     ans <- 0\n#'\n#' #     for(t in 1:(T - 1)) {\n#' #         ans <- ans + cmi(x[, (t):t], y[, (t + 1):(t + 1)], y[, (t):t])\n#' #         print(t, '\\n')\n#' #     }\n#'\n#' #     return(ans)\n#' # }\n\n",
    "created" : 1473191341639.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1996566275",
    "id" : "ABDB31D",
    "lastKnownWriteTime" : 1489540084,
    "last_content_update" : 1489540084552,
    "path" : "~/Dropbox (Personal)/Projects/Genes_Inference_in_Cell_Differentiation_Process/R_package/di/R/function.R",
    "project_path" : "R/function.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}