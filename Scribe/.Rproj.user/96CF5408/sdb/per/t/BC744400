{
    "collab_server" : "",
    "contents" : "// ver 0.1; code review at Oct 2, 2017\n// ver 0.2; update the documentation at Oct 2, 2017\n\n#include <RcppArmadillo.h>\n#include <boost/math/special_functions/digamma.hpp>\n#include <RANNinf.h>\n\n// flann package\n#include <string>\n\n#include \"../inst/include/information_estimator.h\"\n#include \"../inst/include/density.h\"\n\n// #include <ANN/ANN.h> // ANN declarations\n// #include <omp.h>\n// #include \"../inst/include/ann_neighbor_radius.h\"\n// #include \"../inst/include/radius_search.h\"\n// #include \"../inst/include/neighbour.h\"\n\nusing namespace Rcpp;\nusing namespace arma;\nusing namespace boost::math;\nusing namespace RANNinf;\n// using namespace Rcpp::stat\n\n// [[Rcpp::plugins(openmp)]]\n\n// [[Rcpp::depends(RcppArmadillo)]]\n\n//-------------------------------------------------------------------------------------------------------------------\n/*\ncalculate local density  \n*/\n\n// knn_dis = [tree_x.query(point, k_density + 1, p=np.inf)[0][k_density] for point in x]\n// density_estimate = np.array([float(k_density) / N / knn_dis[i] ** dx for i in range(len(knn_dis))])\n//   weight = (1 / density_estimate) / np.mean(1 / density_estimate)\n\nList knn_density_cpp(NumericMatrix x, NumericMatrix y, int k = 5)\n{\n  int dx = x.cols();\n  int N = y.rows(); // number of query points\n  NumericVector weight(N), density_estimate(N); \n\n  int dimension = N;  // k *\n  Rcpp::NumericVector data_y_distances(dimension); \n\n  double error_bound = 0.0; int searchtype = 1; int usebdtree = 0; double sqRad = 0.0; // don't use bd tree (usebdtree = 0)\n\n  get_NN_2Set_cpp(x, y, dx, N, N, k, error_bound, searchtype, usebdtree, sqRad, data_y_distances); //data_xyz_nn_index,\n  \n  // NumericVector vd = 0.5 * d * log(M_PI) - log(gamma(0.5 * d + 1)) + log(data_xyz_distances); // \n  // density_estimate = k / (N * exp(vd)); // this is for the L2 norm (the one below is the infinity norm) \n  density_estimate = k / (N * pow(data_y_distances, dx)); \n  \n  weight = (1 / density_estimate / mean(1 / density_estimate));\n  \n  return List::create(Rcpp::Named(\"density_estimate\") = density_estimate, \n                      Rcpp::Named(\"weight\") = weight);\n}\n\n//' @title\n//' knn_density\n//' @description\n//' This subroutine calculates the 1d density of x at positions y \n//' \n//' @param x 1d vector of the data \n//' @param y 1d vector of querying points, positions used to estimate the density \n//' @param k number of nearest neighbors used to estimate the 1d density, default to be 5 \n//' \n//' @details\n//' \\code{knn_density} takes a vector of original data points x and a vector of querying points y\n//' to calculate the density at each point y using the k-nearest neighbors. \n//' @return a List where the element is the density estimate (name: density_estimate), \n//' the second one is the weight calculated based on density_estimate.  \n//' @export\n// [[Rcpp::export]]\nList knn_density(SEXP x, SEXP y, SEXP k) //&\n{ \n  NumericMatrix x_cpp = as<int>(x); \n  NumericMatrix y_cpp = as<int>(y); \n  int k_cpp = as<int>(k); \n\n  List knn_density_res = knn_density_cpp(x_cpp, y_cpp, k_cpp);\n  return knn_density_res;\n}\n\nNumericMatrix knn_density_2d_cpp(NumericVector x, NumericVector y, IntegerVector nGrids, int k = 5)\n{\n  double x_min = min(x), x_max = max(x);\n  double y_min = min(y), y_max = max(y);\n  double x_step = (x_max - x_min) / (nGrids[0]), y_step = (y_max - y_min) / (nGrids[1]);\n\n  NumericMatrix x_y_grid(nGrids[0] * nGrids[1], 2);\n  NumericMatrix x_y_density(nGrids[0], nGrids[1]);\n\n  for(int i = 0; i < nGrids[0]; i++) \n  {\n    for(int j = 0; j < nGrids[1]; j++)\n    {\n      // make sure we use the middle of each grid \n      x_y_grid(i * nGrids[0] + j, _) = NumericVector::create(x_min + x_step * ((double) i + 0.5), \n                                          y_min + y_step * ((double) j + 0.5) ); \n    }\n  }\n\n  NumericMatrix xy = cbind(x, y);\n  int dxy = 2;\n  int N = xy.rows();\n  int NQ = nGrids[0] * nGrids[1]; \n\n  Rcpp::NumericVector data_xy_distances(nGrids[0] * nGrids[1]), density_estimate(data_xy_distances); \n\n  double error_bound = 0.0; int searchtype = 1; int usebdtree = 0; double sqRad = 0.0; // don't use bd tree (usebdtree = 0)\n\n  get_NN_2Set_cpp(xy, x_y_grid, dxy, N, NQ, k, error_bound, searchtype, usebdtree, sqRad, data_xy_distances); //data_xyz_nn_index,\n  \n  // NumericVector vd = 0.5 * d * log(M_PI) - log(gamma(0.5 * d + 1)) + log(data_xyz_distances); // \n  // density_estimate = k / (N * exp(vd)); // this is for the L2 norm (the one below is the infinity norm) \n  density_estimate = k / (N * pow(data_xy_distances, dxy));  \n\n  for(int i = 0; i < nGrids[0]; i++) \n  {\n    for(int j = 0; j < nGrids[1]; j++)\n    {\n      x_y_density(i, j) = density_estimate[i * nGrids[0] + j]; \n    }\n  }\n\n  return(x_y_density);\n}\n\n// enable Gaussian smoothing \n//' @title\n//' knn_density_2d\n//' @description\n//' This subroutine calculates the density for a 2d space. \n//' \n//' @param x A vector for the values of the data on the first dimension \n//' @param y A vector for the values of the data on the second dimension \n//' @param nGrids A vector of two for the grid numbers on the first and second dimension \n//' @param k number of nearest neighbors used to calculate the 2d density \n//' \n//' @details\n//' \\code{knn_density_2d} \n//' @return a numeric value for the d-dimensional unit ball for Euclidean norm\n//' @export a matrix of density estimate, calculated on the center of each grid from the data x and y. \n// [[Rcpp::export]]\nNumericMatrix knn_density_2d(SEXP x, SEXP y, SEXP nGrids, SEXP k) //&\n{ \n  NumericVector x_cpp = as<int>(x); \n  NumericVector y_cpp = as<int>(y); \n  IntegerVector nGrids_cpp = as<int>(nGrids); \n  int k_cpp = as<int>(k); \n\n  NumericMatrix knn_density_2d_res = knn_density_2d_cpp(x_cpp, y_cpp, nGrids_cpp, k_cpp);\n  return knn_density_2d_res;\n}\n\n/*\n knn_density(1:10, 5)\n knn_density(matrix(1:100, ncol = 1), 5)\n \n density(1:100, bw = 1, n = 100, from = 1, to = 100)$y\n \n cpp <- knn_density(matrix(1:100, ncol = 1), 5)\n Rversion <- 1 / density(1:100, bw = 0.2, n = 100, from = 1, to = 100)$y / mean(1 / density(1:100, bw = 0.2, n = 100, from = 1, to = 100)$y)\n \n qplot(cpp, Rversion)\n \n// NumericVector Cquantile(NumericVector x, NumericVector q) \n// {\n//   NumericVector y = clone(x);\n//   std::sort(y.begin(), y.end());\n//   return y[x.size()*(q - 0.000000001)];\n// }\n\n// NumericVector Cquantile(NumericVector x, NumericVector probs) {\n//   Environment stats(\"package:stats\");\n//   Function quantile = stats[\"quantile\"];\n//   int npr = probs.size();\n//   NumericVector ans(npr);\n//   for(int i=0; i<npr; i++){\n//     ans[i] = as<double>(quantile(x, probs[i]));\n//   }\n//   return ans;\n// }\n\n// double bandwidth_nrd_cppfunction(NumericVector x)\n// {\n//     NumericVector r = Cquantile(x, NumericVector::create(0.25, 0.75));\n//     double h = (r[2] - r[1])/1.34;\n//     double res = 4 * 1.06 * min(NumericVector::create(sqrt(var(x)), h)) * pow(x.size(), (-1/5));\n\n//     return(res);\n// }\n√•\n */\n\n// [[Rcpp::export]]\ndouble digamma_0(double x) // this modified digamma function avoids the undefined case for 0 \n{\n  if(x == 0)\n  {\n   return digamma(1); // arma::datum::inf\n  }\n  else {\n    return digamma(x);\n  }\n}\n//-------------------------------------------------------------------------------------------------------------------\n/*\n  calculate vd \n*/\n//-------------------------------------------------------------------------------------------------------------------\n\n//'  This subroutine calculates the volume of a d-dimensional unit ball for Euclidean norm\ndouble vd_cpp(const int d)\n{\n  double vd_res = 0.5 * d * log(M_PI) - log(gamma(0.5 * d + 1));\n  return vd_res;\n}\n\n//' @title\n//' vd\n//' @description\n//' This subroutine calculates the volume of a d-dimensional unit ball for Euclidean norm\n//' \n//' @param d number of dimension\n//' \n//' @details\n//' \\code{vd} takes a integer of dimensions and then calculate the volume of a d-dimensional unit ball for Euclidean norm\n//' using the formula: 0.5 * d * log(pi) - log(gamma(0.5 * d + 1))\n//' It's implimented in C++, providing a (small) increase in speed over the R equivalent.\n//' @return a numeric value for the d-dimensional unit ball for Euclidean norm\n//' @export\n// [[Rcpp::export]]\ndouble vd(SEXP d) //&\n{ \n  int d_cpp = as<int>(d); \n  double vd_res = vd_cpp(d_cpp);\n  return vd_res;\n}\n\n//-------------------------------------------------------------------------------------------------------------------\n/*\n  calculate entropy \n*/\n//-------------------------------------------------------------------------------------------------------------------\n\n//' This function estimates the entropy of a continuous random variable\ndouble entropy_cpp(const NumericMatrix& x, int k) // = 5 NumericVector\n{\n  int N = x.rows();\n  if(k > N)\n  {\n    stop(\"k is larger than total number of samples\");\n    return -1;\n  }\n  \n  int d = x.cols();\n  \n  int dimension = N;  //k *\n  Rcpp::NumericVector distances(dimension);\n\n  // Rcpp::IntegerVector nn_index; \n  // nn_index = IntegerVector(dimension);\n\n  // use ANN: \n  double error_bound = 0.0; int searchtype = 1; int usebdtree = 0; double sqRad = 0.0; \n  \n  get_NN_2Set_cpp(x, x, d, N, N, k, error_bound, searchtype, usebdtree, sqRad, distances); //, *nn_index, *distances\n  \n  // // use flann: \n  // int cores = 1, checks = 1; std::string build(\"kdtree\");  \n  // NumericVector distances = Neighbour(x, k, build, cores, checks); \n\n  NumericVector log_knn_dist(N);\n  for(int i = 0; i < N; i++)\n  {\n    log_knn_dist[i] = log(distances[i]); //(i + 1) * k - 1\n  }\n\n  double entropy = - digamma_0(k) + digamma_0(N) + d * mean(log_knn_dist); \n  return entropy;\n}\n\n//' @title\n//' entropy\n//' @description\n//' This subroutine estimates the entropy of a continuous random variable\n//' \n//' @param x data matrix used for calculating the entropy\n//' \n//' @param k number for nearest neighbors used in entropy calculation\n//'\n//' @details\n//' \\code{entropy} takes a continuous random variable and then estimates\n//' entropy using the KSG estimator. \n//' It relies on the ANN package to query the kNN with KDTree algorithm.  \n//' @return a numeric value of entropy estimate\n//' @export\n// [[Rcpp::export]]\ndouble entropy(SEXP x, SEXP k) //\n{ \n  NumericMatrix x_cpp(x);\n  int k_cpp = as<int>(k);\n\n  double entropy = entropy_cpp(x_cpp, k_cpp); \n  return(entropy);\n}\n\n//-------------------------------------------------------------------------------------------------------------------\n/*\n  calculate mutual information \n*/\n//-------------------------------------------------------------------------------------------------------------------\n\n// This function estimates the mutual information of two random variables based on their observed values\ndouble mi_cpp(const NumericMatrix& x, const NumericMatrix& y, int k, int normalize) \n{\n\n  k = k + 1; // the first nearest point is itself in ANN\n\n  int N = x.rows();\n  NumericMatrix data = cbind(x, y); int d_data = data.cols();\n  \n\tint dx = x.cols();\tint dy = y.cols(); \n\n\tif(k > N)\n  {\n    stop(\"k is larger than total number of samples\");\n    return -1;\n  }\n  if(y.rows() != N)\n  {\n    stop(\"Number of samples should be the same\");\n    return -1;\n  }\n\n  // use ANN \n  double error_bound = 0.0; int searchtype = 1; int usebdtree = 0; double sqRad = 0.0; int x_y_k = 0;\n\n  int dimension =  N;  //k *\n  Rcpp::NumericVector data_distances(dimension); \n  \n  get_NN_2Set_cpp(data, data, d_data, N, N, k, error_bound, searchtype, usebdtree, sqRad,  data_distances); //data_nn_index,\n  \n  // // use flann: \n  // int cores = 1, checks = 1; std::string build(\"kdtree\"); \n  // NumericVector data_distances = Neighbour(data, k, build, cores, checks); \n \n\tNumericVector information_samples(N, digamma_0(N));\n\n  NumericVector k_xy = get_points_in_radius_cpp(data, data, d_data, N, N, x_y_k, error_bound, usebdtree, data_distances);\n  NumericVector cnt_x = get_points_in_radius_cpp(x, x, dx, N, N, x_y_k, error_bound, usebdtree, data_distances);\n  NumericVector cnt_y = get_points_in_radius_cpp(y, y, dy, N, N, x_y_k, error_bound, usebdtree, data_distances); \n  \n  // remove it self \n  k_xy = k_xy - 1;\n  cnt_x = cnt_x - 1;\n  cnt_y = cnt_y - 1; \n  // // use flann: \n  // NumericVector k_xy = RadiusSearch(data, data_distances, build, cores, checks); \n  // NumericVector cnt_x = RadiusSearch(x, data_distances, build, cores, checks); \n  // NumericVector cnt_y = RadiusSearch(y, data_distances, build, cores, checks); \n\n  int i; \n\n  // int max_thread = omp_get_max_threads();\n  // omp_set_num_threads(max_thread);\n  // #pragma omp parallel for shared(information_samples, N, cnt_x, cnt_y) private(i) //schedule(dynamic) default(none) //collapse(2) , _\n  for(i = 0; i < N; i++)\n  {\n    information_samples[i] += digamma_0(k_xy[i]) - digamma_0(cnt_x[i]) - digamma_0(cnt_y[i]);\n  }\n\n  NumericVector weight(N);\n  weight = weight + 1.0;\n\n  List knn_density_res; \n\n  if(normalize != 0) {\n    knn_density_res = knn_density_cpp(x, x, k); \n    weight = knn_density_res[\"weight\"];\n  }\n\n\tdouble mi_res = mean(information_samples * weight); //\n\n\treturn mi_res;\n}\n\n//' @title\n//' mi\n//' @description\n//' This function estimates the mutual information of two random variables, x, y, based on their observed values\n//' \n//' @param x one random variable from the time-series data\n//' \n//' @param y another random variable from the time-series data\n//'\n//' @param k number for nearest neighbors used in entropy calculation\n//'\n//' @param normalize A logic flag to determine whether or not you want to normalize the MI value by the density of x. \n//'\n//' @details\n//' \\code{mi} takes two random variables x and y to estimate the mutual information between them \n//' using the KSG estimator\n//' It relies on the ANN package to query the kNN with KDTree algorithm. \n//' @return a estimated mutual information value between two variables (x, y)\n//' @export\n// [[Rcpp::export]]\ndouble mi(SEXP x, SEXP y, SEXP k, SEXP normalize) //&\n{ \n  NumericMatrix x_cpp(x); \n  NumericMatrix y_cpp(y); \n  int k_cpp = as<int>(k);\n  int normalize_cpp = as<int>(normalize);\n\n  double mi_res = mi_cpp(x_cpp, y_cpp, k_cpp, normalize_cpp);\n\n  return mi_res;\n}\n\n//-------------------------------------------------------------------------------------------------------------------\n/*\n  calculate conditional mutual information \n*/\n//-------------------------------------------------------------------------------------------------------------------\n\n//' This function estimates the CONDITIONAL mutual information of X and Y given Z\n//' Multiply a number by two\n//'\nList cmi_cpp(const NumericMatrix& x, const NumericMatrix& y, NumericMatrix z, int k, int normalize){ // const NumericMatrix& z, \n  \n  k = k + 1; \t\n\n  int N = x.rows();\n  if(y.rows() != N | z.rows() != N)\n  {\n    stop(\"all Matrix should include the same number of samples\");\n  }\n\n  NumericMatrix data_xz = cbind(x, z);\n  NumericMatrix data_yz = cbind(y, z);\n  NumericMatrix data_xyz = cbind(cbind(x, y), z);\n\n  int dxz = data_xz.cols();  int dyz = data_yz.cols(); int dz = z.cols(); int d_data_xyz = data_xyz.cols();\n\n  double error_bound = 0.0; int searchtype = 1; int usebdtree = 0; double sqRad = 0.0; int cmbn_k = 0; // don't use bd tree (usebdtree = 0)\n\n  int dimension = N;  // number of cells \n  Rcpp::NumericVector data_xyz_distances(dimension); \n\n  get_NN_2Set_cpp(data_xyz, data_xyz, d_data_xyz, N, N, k, error_bound, searchtype, usebdtree, sqRad, data_xyz_distances); //data_xyz_nn_index,\n\n  NumericVector information_samples(N);\n\n  NumericVector k_xyz = get_points_in_radius_cpp(data_xyz, data_xyz, d_data_xyz, N, N, cmbn_k, error_bound, usebdtree, data_xyz_distances);\n  NumericVector cnt_xz = get_points_in_radius_cpp(data_xz, data_xz, dxz, N, N, cmbn_k, error_bound, usebdtree, data_xyz_distances);\n  NumericVector cnt_yz = get_points_in_radius_cpp(data_yz, data_yz, dyz, N, N, cmbn_k, error_bound, usebdtree, data_xyz_distances); \n\n  NumericVector cnt_z = get_points_in_radius_cpp(z, z, dz, N, N, cmbn_k, error_bound, usebdtree, data_xyz_distances); \n\n  k_xyz = k_xyz - 1;\n  cnt_xz = cnt_xz - 1; \n  cnt_yz = cnt_yz - 1; \n  cnt_z = cnt_z - 1; \n\n  int i;\n  // int max_thread = omp_get_max_threads();\n  // omp_set_num_threads(max_thread);\n  // #pragma omp parallel for shared(information_samples, N, cnt_xz, cnt_yz, cnt_z) private(i) //schedule(dynamic) default(none) //collapse(2) , _\n  for(i = 0; i < N; i++)\n  {\n    if(k_xyz[i] == 0 | cnt_xz[i] == 0 | cnt_yz[i] == 0 | cnt_z[i] == 0)\n      continue; \n    \n    information_samples[i] += digamma_0(k_xyz[i]) - digamma_0(cnt_xz[i]) - digamma_0(cnt_yz[i]) + digamma_0(cnt_z[i]); \n  }\n\n  NumericVector weight(N);\n  weight = weight + 1.0;\n\n  List knn_density_res; \n\n  if(normalize != 0) {\n    knn_density_res = knn_density_cpp(x, x, k);  // try data_xz\n    weight = knn_density_res[\"weight\"]; \n  }\n  \n  double cmi_res = mean(information_samples * weight);//mean(information_samples);\n\n  // if(arma::is_finite(cmi_res) == false) \n  // {\n  //   Rcout << \"weight is \" << weight << std::endl;\n  //   Rcout << \"cmi_res is \" << cmi_res << std::endl;\n  //   stop(\"cmi_res is NaN or NA values!\");\n  // }\n\n  return List::create(Rcpp::Named(\"cmi_res\") = cmi_res, \n            Rcpp::Named(\"information_samples\") = information_samples); \n}\n\n//' @title\n//' cmi\n//' @description\n//' This subroutine calculates the volume of a d-dimensional unit ball for Euclidean norm\n//' \n//' @param x one random variable from the time-series data\n//' \n//' @param y another random variable from the time-series data\n//'\n//' @param z condition random variable for variables (x, y) from the time-series data\n//'\n//' @param k number for nearest neighbors used in entropy calculation\n//'\n//' @param normalize A logic flag to determine whether or not you want to normalize the MI value by the density of x. \n//'\n//' @details\n//' \\code{cmi} takes two random variable x and y and estimated their mutual information conditioned on the third random variable z\n//' using the KSG estimator. \n//' It relies on the ANN package to query the kNN with KDTree algorithm. \n//' @return a estimated conditional mutual information value between two variables (x, y), conditioning on a third variable z. \n//' @export\n// [[Rcpp::export]]\nList cmi(SEXP x, SEXP y, SEXP z, SEXP k, SEXP normalize) \n{ \n  NumericMatrix x_cpp(x); \n  NumericMatrix y_cpp(y); \n  NumericMatrix z_cpp(z); \n\n  int k_cpp = as<int>(k); \n  int normalize_cpp = as<int>(normalize); \n\n  List cmi_res = cmi_cpp(x_cpp, y_cpp, z_cpp, k_cpp, normalize_cpp);\n  return cmi_res;\n}\n\n// List ucmi_res = ucmi_cpp(x_cpp, y_cpp, z_cpp, k_cpp, method_cpp, k_density_cpp, bw_cpp);\n// [[Rcpp::interfaces(r, cpp)]]\n// [[Rcpp::export]]\nList ucmi_cpp(const NumericMatrix& x, const NumericMatrix& y, NumericMatrix z, int k, int method, int k_density, double bw){ // , NumericVector weight const NumericMatrix& z, \n  \n  k = k + 1;  \n\n  int N = x.rows();\n  if(y.rows() != N | z.rows() != N)\n  {\n    stop(\"all Matrix should include the same number of samples\");\n  }\n\n  NumericMatrix data_xz = cbind(x, z);\n  NumericMatrix data_yz = cbind(y, z);\n  NumericMatrix data_xyz = cbind(cbind(x, y), z);\n\n  int dxz = data_xz.cols();  int dyz = data_yz.cols(); int dz = z.cols(); int d_data_xyz = data_xyz.cols();\n\n  double error_bound = 0.0; int searchtype = 1; int usebdtree = 0; double sqRad = 0.0; int cmbn_k = 0; // don't use bd tree (usebdtree = 0)\n\n  // kde_cpp(NumericMatrix data, int k = 1, int b = 1, int pdf = 1, int density_sample_type = 1)\n  NumericVector weight; //(N)\n  \n  if(method == 1) {\n    int k = 1, b = 1, pdf = 1, density_sample_type = 1;\n    NumericMatrix kde_mat; // NumericMatrix kde_cpp\n    \n    kde_mat = kde_cpp(data_xz, k, b, pdf, density_sample_type); // get the density\n    weight = kde_mat(_, 0); // get the density estimator\n    // weight = exp(weight);\n\n    weight = (1 / weight) / mean(1 / weight); // convert the density estimator into weight estimate\n  } else if(method == 2) {\n    List knn_density_res; \n    knn_density_res = knn_density_cpp(x, x, k);  // try data_xz\n    weight = knn_density_res[\"weight\"]; \n  }\n\n  int dimension = N;  // number of cells \n  Rcpp::NumericVector data_xyz_distances(dimension); \n\n  get_NN_2Set_cpp(data_xyz, data_xyz, d_data_xyz, N, N, k, error_bound, searchtype, usebdtree, sqRad, data_xyz_distances); //data_xyz_nn_index,\n\n  NumericVector information_samples(N);\n\n  NumericVector k_xyz = get_points_in_radius_cpp(data_xyz, data_xyz, d_data_xyz, N, N, cmbn_k, error_bound, usebdtree, data_xyz_distances);\n  NumericVector cnt_xz = get_points_in_radius_cpp(data_xz, data_xz, dxz, N, N, cmbn_k, error_bound, usebdtree, data_xyz_distances);\n  \n  List yz_list = get_points_indices_in_radius_cpp(data_yz, data_yz, dyz, N, N, cmbn_k, error_bound, usebdtree, data_xyz_distances); \n  IntegerMatrix yz_neighbors = yz_list[\"nn_index\"];\n  NumericVector yz_num_cnts = yz_list[\"num_cnts\"]; \n  \n  List z_list = get_points_indices_in_radius_cpp(z, z, dz, N, N, cmbn_k, error_bound, usebdtree, data_xyz_distances); \n  IntegerMatrix z_neighbors = z_list[\"nn_index\"]; \n  NumericVector z_num_cnts = z_list[\"num_cnts\"]; \n  \n  k_xyz = k_xyz - 1;\n  cnt_xz = cnt_xz - 1; \n  // cnt_yz = cnt_yz - 1; \n  // cnt_z = cnt_z - 1; \n\n  int i, current_neighbor_cnt;\n  IntegerVector yz_neighbors_ind, z_neighbors_ind; \n  weight[is_na(weight)] = 1; // convert the na values into 1  \n\n  Rcout << \"weight vector is \" << weight << std::endl;\n  // int max_thread = omp_get_max_threads();\n  // omp_set_num_threads(max_thread);\n  // #pragma omp parallel for shared(information_samples, N, cnt_xz, cnt_yz, cnt_z) private(i) //schedule(dynamic) default(none) //collapse(2) , _\n  // std::ofstream file(\"test_ucmi_cpp.txt\");\n  \n  for(i = 0; i < N; i++)\n  {\n    if(k_xyz[i] == 0 | cnt_xz[i] == 0) // | cnt_yz[i] == 0 | cnt_z[i] == 0\n      continue; \n    \n    // information_samples[i] += weight[i]* digamma(len(tree_xyz.query_ball_point(data_xyz[i], knn_dis[i], p=np.inf )) -1)\n    // information_samples[i] += weight[i]* -digamma(len(tree_xz.query_ball_point(data_xz[i], knn_dis[i], p=np.inf )) - 1)\n    // information_samples[i] += weight[i]* -digamma( np.sum( weight[j] for j in tree_yz.query_ball_point(data_yz[i], knn_dis[i], p=np.inf )) - weight[i])\n    // information_samples[i] += weight[i]* digamma( np.sum( weight[j] for j in tree_z.query_ball_point(z[i], knn_dis[i], p=np.inf)) - weight[i])\n    current_neighbor_cnt = yz_num_cnts[i] - 1;\n    yz_neighbors_ind = yz_neighbors(i, _); \n    yz_neighbors_ind = yz_neighbors_ind[Range(0, current_neighbor_cnt)]; \n    \n    current_neighbor_cnt = z_num_cnts[i] - 1;\n    z_neighbors_ind = z_neighbors(i, _); \n    z_neighbors_ind = z_neighbors_ind[Range(0, current_neighbor_cnt)];\n\n    NumericVector sub_weight_yz = weight[yz_neighbors_ind]; double digamma_0_yz = sum(sub_weight_yz) - weight[i];\n    NumericVector sub_weight_z = weight[z_neighbors_ind]; double digamma_0_z = sum(sub_weight_z) - weight[i];\n    \n    // if (file.is_open() && i < 5)\n    // {\n    //   file << \"current yz_neighbors_ind ind is \" << yz_neighbors_ind << '\\n';\n    //   file << \"current z_neighbors_ind ind is \" << z_neighbors_ind << '\\n';\n    //   file << \"weight is \" << weight << \"\\n\"; \n    //   file << \"sub_weight_yz is \" << sub_weight_yz << \"\\n\"; \n    //   file << \"sub_weight_z is \" << sub_weight_z << \"\\n\"; \n    //   file << \"digamma_0_yz is \" << digamma_0_yz << \"\\n\"; \n    //   file << \"digamma_0_z is \" << digamma_0_z << \"\\n\"; \n    // }\n    \n    information_samples[i] += weight[i] * digamma_0(k_xyz[i]); \n    information_samples[i] -= weight[i] * digamma_0(cnt_xz[i]);\n    information_samples[i] -= weight[i] * digamma_0(digamma_0_yz);\n    information_samples[i] += weight[i] * digamma_0(digamma_0_z); \n  }\n\n  double ucmi_res = mean(information_samples); //mean(information_samples);\n\n  // if(arma::is_finite(cmi_res) == false) \n  // {\n  //   Rcout << \"weight is \" << weight << std::endl;\n  //   Rcout << \"cmi_res is \" << cmi_res << std::endl;\n  //   stop(\"cmi_res is NaN or NA values!\");\n  // }\n\n  return List::create(Rcpp::Named(\"ucmi_res\") = ucmi_res, \n            Rcpp::Named(\"information_samples\") = information_samples,\n            Rcpp::Named(\"weight\") = weight); \n}\n\n//' @title\n//' ucmi\n//' @description\n//' This subroutine calculates the uniformed conditional mutual information where \n//' the distribution for x and z is replaced by a uniform distribution.  \n//' \n//' @param x one random variable from the time-series data\n//' @param y another random variable from the time-series data\n//' @param z condition random variable for variables (x, y) from the time-series data\n//' @param k number for nearest neighbors used in entropy calculation\n//' @param method Which 2D density estimator you would like to use. 1 is kde estimator and 2 is knn based estimator. \n//' @param k_density The number of k nearest neighbors you would like to use when calculating the density \n//' (only applicable when method == 2 or using knn based density estimation). \n//' @param bw Bindwidth used for the kernel density estimator. Currently it is not used. The bindwidth in the kde function is automatically estimated. \n//' \n//' @details\n//' \\code{ucmi} takes two random variable x and y and estimated their mutual information conditioned on the third random variable z\n//' using the KSG estimator while x, y is replaced by a uniform distribution. It relies on a C++ implmentation of kde estimator \n//' (https://github.com/timnugent/kernel-density) and the ANN package to query the kNN with KDTree algorithm. \n//' @return  a estimated conditional mutual information value between two variables (x, y), conditioning on a third variable z where \n//' the distribution for the x, z is replaced by a uniform distribution. \n//'  \n//' @export\n// [[Rcpp::export]]\nList ucmi(SEXP x, SEXP y, SEXP z, SEXP k, SEXP method, SEXP k_density, SEXP bw) //, SEXP weight\n{ \n  NumericMatrix x_cpp(x); \n  NumericMatrix y_cpp(y); \n  NumericMatrix z_cpp(z); \n\n  int k_cpp = as<int>(k); \n\n  int method_cpp = as<int>(method); \n  int k_density_cpp = as<int>(k_density);\n  double bw_cpp = as<double>(bw); \n\n  // NumericVector weight_cpp = as<NumericVector>(weight); \n  \n  List ucmi_res = ucmi_cpp(x_cpp, y_cpp, z_cpp, k_cpp, method_cpp, k_density_cpp, bw_cpp); //, weight_cpp\n  return ucmi_res;\n}\n\n// [[Rcpp::interfaces(r, cpp)]]\n// [[Rcpp::export]]\ndouble umi_cpp(const NumericMatrix& x, const NumericMatrix& y, int k, int method, int k_density, double bw) // , NumericVector weight\n{ \n  \n  k = k + 1; // the first nearest point is itself in ANN\n\n  int N = x.rows();\n  NumericMatrix data = cbind(x, y); int d_data = data.cols();\n  \n  int dx = x.cols();  int dy = y.cols(); \n\n  if(k > N)\n  {\n    stop(\"k is larger than total number of samples\");\n    return -1;\n  }\n  if(y.rows() != N)\n  {\n    stop(\"Number of samples should be the same\");\n    return -1;\n  }\n\n  // kde_cpp(NumericMatrix data, int k = 1, int b = 1, int pdf = 1, int density_sample_type = 1)\n  NumericVector weight; //(N)\n\n  if(method == 1) {\n    int k = 1, b = 1, pdf = 1, density_sample_type = 1;\n    NumericMatrix kde_mat; // NumericMatrix kde_cpp\n\n    kde_mat = kde_cpp(x, k, b, pdf, density_sample_type); // get the density\n    weight = kde_mat(_, 0); // get the density estimator\n    // weight = exp(weight);\n\n    weight = (1 / weight) / mean(1 / weight); // convert the density estimator into weight estimate\n  } else if(method == 2) {\n    List knn_density_res;\n    knn_density_res = knn_density_cpp(x, x, k);  // try data_xz\n    weight = knn_density_res[\"weight\"];\n  }\n\n  // use ANN \n  double error_bound = 0.0; int searchtype = 1; int usebdtree = 0; double sqRad = 0.0; int x_y_k = 0;\n\n  int dimension =  N;  \n  Rcpp::NumericVector data_distances(dimension); \n  \n  get_NN_2Set_cpp(data, data, d_data, N, N, k, error_bound, searchtype, usebdtree, sqRad,  data_distances); //data_nn_index,\n  \n  NumericVector k_xy = get_points_in_radius_cpp(data, data, d_data, N, N, x_y_k, error_bound, usebdtree, data_distances);\n  NumericVector cnt_x = get_points_in_radius_cpp(x, x, dx, N, N, x_y_k, error_bound, usebdtree, data_distances);\n  // NumericVector cnt_y = get_points_in_radius_cpp(y, y, dy, N, N, x_y_k, error_bound, usebdtree, data_distances); \n\n  List y_list = get_points_indices_in_radius_cpp(y, y, dy, N, N, x_y_k, error_bound, usebdtree, data_distances); \n  IntegerMatrix y_neighbors = y_list[\"nn_index\"];\n  NumericVector y_num_cnts = y_list[\"num_cnts\"]; \n    \n  // remove it self \n  k_xy = k_xy - 1;\n  cnt_x = cnt_x - 1;\n\n  NumericVector weight_y(N); //(N)\n\n  double ans = digamma_0(k - 1) + 2 * log(N - 1) - digamma_0(N); // + vd(dx) + vd(dy) - vd(dx + dy) \n\n  int i, current_neighbor_cnt, nx;\n  double ny;\n  IntegerVector y_neighbors_ind;\n  NumericVector tmp; \n  \n  // int max_thread = omp_get_max_threads();\n  // omp_set_num_threads(max_thread);\n  // #pragma omp parallel for shared(information_samples, N, cnt_x, cnt_y) private(i) //schedule(dynamic) default(none) //collapse(2) , _\n  for(i = 0; i < N; i++)\n  {\n    nx = cnt_x[i];\n\n    current_neighbor_cnt = y_num_cnts[i] - 1;\n    y_neighbors_ind = y_neighbors(i, _); \n    y_neighbors_ind = y_neighbors_ind[Range(0, current_neighbor_cnt)]; \n    tmp = weight[y_neighbors_ind]; \n    ny = sum(tmp) - weight[i];\n\n    ans += -weight[i] * log(nx) / N;\n    ans += -weight[i] * log(ny) / N; \n  }\n\n  return ans;\n}\n\n//' @title\n//' umi\n//' @description\n//' This subroutine calculates the uniformed  mutual information where \n//' the distribution for x is replaced by a uniform distribution.  \n//' \n//' @param x one random variable from the time-series data\n//' @param y another random variable from the time-series data\n//' @param k number for nearest neighbors used in entropy calculation\n//' @param method Which 2D density estimator you would like to use. 1 is kde estimator and 2 is knn based estimator. \n//' @param k_density The number of k nearest neighbors you would like to use when calculating the density \n//' (only applicable when method == 2 or using knn based density estimation). \n//' @param bw Bindwidth used for the kernel density estimator. Currently it is not used. The bindwidth in the kde function is automatically estimated. \n//' \n//' @details\n//' \\code{umi} takes two random variable x and y and estimated their mutual using the KSG estimator while x is replaced by a uniform distribution. \n//' It relies on a C++ implmentation of kde estimator (https://github.com/timnugent/kernel-density) and the ANN package to query the kNN with KDTree algorithm. \n//' @return  A estimated uniform mutual information value between two variables (x, y) where the distribution for the x is replaced by a uniform distribution. \n//'  \n//' @export\n// [[Rcpp::export]]\ndouble umi(SEXP x, SEXP y, SEXP k, SEXP method, SEXP k_density, SEXP bw)\n{ \n  NumericMatrix x_cpp(x); \n  NumericMatrix y_cpp(y); \n\n  int k_cpp = as<int>(k); \n\n  int method_cpp = as<int>(method); \n  int k_density_cpp = as<int>(k_density);\n  double bw_cpp = as<double>(bw); \n  \n  double ucmi_res = umi_cpp(x_cpp, y_cpp, k_cpp, method_cpp, k_density_cpp, bw_cpp);\n  return ucmi_res;\n}\n\n/*** R\nlibrary(MASS)\nlibrary(Scribe)\nlung <- load_lung()\nx <- exprs(lung)[, 1]\ny <- exprs(lung)[, 2]\nx <- log(x + 1)\ny <- log(y + 1)\ndata_xy <- matrix(c(x, y), ncol = 2, byrow = T)\nres <- kde2d(x, y)\ncontour(res, xlab = \"previous duration\",\n        ylab = \"duration\", levels  =  c(0.05, 0.1, 0.2, 0.4) )\nkde_cpp_res <- kde_cpp(data_xy)\nx_d = x[-length(y)]\ny_d = y[-length(y)]\ny_t = y[-1]\nucmi(x_d, y_t, y_d, k = 5, method == 1, k_density = 0, bw = 0)\n\nattach(geyser)\nplot(duration, waiting, xlim = c(0.5,6), ylim = c(40,100))\nf1 <- kde2d(duration, waiting, n = 50, lims = c(0.5, 6, 40, 100))\n\ndata_xy <- matrix(c(duration, duration), ncol = 2, byrow = F)\nkde_cpp_res <- kde_cpp(data_xy)\n\n##############################################################################################################################\n# test the result vs the python implmentation \n##############################################################################################################################\nx <- read.csv('/Users/xqiu/Dropbox (Personal)/Projects/Causal_network/causal_network/Python_code/x_ucmi.txt', header = F)\ny <- read.csv('/Users/xqiu/Dropbox (Personal)/Projects/Causal_network/causal_network/Python_code/y_ucmi.txt', header = F)\nz <- read.csv('/Users/xqiu/Dropbox (Personal)/Projects/Causal_network/causal_network/Python_code/z_ucmi.txt', header = F)\n\ncmi_res <- cmi(as.matrix(x, ncol = 1), as.matrix(y, ncol = 1), as.matrix(z, ncol = 1), k = 5L, 0L)\nucmi_res <- ucmi(as.matrix(x, ncol = 1), as.matrix(y, ncol = 1), as.matrix(z, ncol = 1), k = 5, method = 1, k_density = 0, bw = 0)\ncmi_res$cmi_res\nucmi_res$ucmi_res\n\ncmi_res <-cmi(as.matrix(x^2, ncol = 1), as.matrix(y^2, ncol = 1), as.matrix(z^2, ncol = 1), k = 5L, 0L)\nucmi_res <-ucmi(as.matrix(x^2, ncol = 1), as.matrix(y^2, ncol = 1), as.matrix(z^2, ncol = 1), k = 5, method = 1, k_density = 0, bw = 0)\ncmi_res$cmi_res\nucmi_res$ucmi_res\n\ncmi_res <-cmi(as.matrix(x^3, ncol = 1), as.matrix(y^3, ncol = 1), as.matrix(z^3, ncol = 1), k = 5L, 0L)\nucmi_res <-ucmi(as.matrix(x^3, ncol = 1), as.matrix(y^3, ncol = 1), as.matrix(z^3, ncol = 1), k = 5, method = 1, k_density = 0, bw = 0)\ncmi_res$cmi_res\nucmi_res$ucmi_res\n\ncmi_res <-cmi(as.matrix(x^4, ncol = 1), as.matrix(y^4, ncol = 1), as.matrix(z^4, ncol = 1), k = 5L, 0L)\nucmi_res <- ucmi(as.matrix(x^4, ncol = 1), as.matrix(y^4, ncol = 1), as.matrix(z^4, ncol = 1), k = 5, method = 1, k_density = 0, bw = 0)\ncmi_res$cmi_res\nucmi_res$ucmi_res\n\nx5 <- read.csv('/Users/xqiu/Dropbox (Personal)/Projects/Causal_network/causal_network/Python_code/x10_ucmi.txt', header = F)\ny5 <- read.csv('/Users/xqiu/Dropbox (Personal)/Projects/Causal_network/causal_network/Python_code/y10_ucmi.txt', header = F)\nz5 <- read.csv('/Users/xqiu/Dropbox (Personal)/Projects/Causal_network/causal_network/Python_code/z10_ucmi.txt', header = F)\nweight <- read.csv('/Users/xqiu/Dropbox (Personal)/Projects/Causal_network/causal_network/Python_code/weight.txt', header = F)\n\ndata_xy <- matrix(c(x5[, 1], z5[, 1]), ncol = 2, byrow = F)\nkde_cpp_res <- kde_cpp(as.matrix(data_xy)) # this is very slow \nkde_res <- kde2d(data_xy)\n\na <- Sys.time()\ncmi_res <-cmi(as.matrix(x5, ncol = 1), as.matrix(y5, ncol = 1), as.matrix(z5, ncol = 1), k = 5L, 0L)\nb <- Sys.time()\n\nk = 1\nb = 1\npdf = 1\ndensity_sample_type = 1;\n\ndata_xz <- matrix(x5, z5, ncol = 2)\n\na <- Sys.time()\nucmi_res <-ucmi(as.matrix(x5, ncol = 1), as.matrix(y5, ncol = 1), as.matrix(z5, ncol = 1), k = 5, method = 1, k_density = 0, bw = 0)\nb <- Sys.time()\n\nucmi_res <-ucmi(as.matrix(x5, ncol = 1), as.matrix(y5, ncol = 1), as.matrix(z5, ncol = 1), k = 5, method = 1, k_density = 0, bw = 0)\n\n\na <- Sys.time()\nkde_cpp_res <- kde_cpp(as.matrix(data_xz), k = 1, b = 1, pdf = 1, density_sample_type = 2) # this is very slow \nb <- Sys.time()\nb - a \n\n# compare between python and cpp for the neuron dataset: \ndata_xy <- matrix(c(x5[, 1], z5[, 1]), ncol = 2, byrow = F)\na <- Sys.time()\nkde_cpp_res <- kde_cpp(as.matrix(data_xz), k = 1, b = 1, pdf = 1, density_sample_type = 2) # this is very slow \n  b <- Sys.time()\n  b - a \n\numi(as.matrix(x5, ncol = 1), as.matrix(y5, ncol = 1), k = 5, method = 1, k_density = 5, bw = 0.01)\nweight_umi\nweight_umi <- read.csv('/Users/xqiu/Dropbox (Personal)/Projects/Causal_network/causal_network/Python_code/weight_umi.txt', header = F)\nkde_cpp_res <- kde_cpp(as.matrix(x5)) # this is very slow \nqplot(t((1 / kde_cpp_res) / mean(1 / kde_cpp_res)), weight_umi)\n\n#!/usr/bin/Rscript\nfilename <- \"univariate_pdf.png\"\ndata <- read.table(\"/Users/xqiu/Dropbox (Personal)/Projects/Causal_network/causal_network/Cpp/Real_deal/Scribe/kernel-density/data/multivariate.csv\", header=FALSE, sep=\",\" ,comment.char=\"#\")\n  png(filename)\n  plot(data$V1,data$V2,xlab=\"x\",ylab=\"density\",main=\"Univariate PDF\")\n  x <-dev.off()\n  \n  filename <- \"univariate_cdf.png\"\ndata <- read.table(\"/Users/xqiu/Dropbox (Personal)/Projects/Causal_network/causal_network/Cpp/Real_deal/Scribe/kernel-density/data/multivariate.csv\", header=FALSE, sep=\",\" ,comment.char=\"#\")\n  png(filename)\n  plot(data$V1,data$V2,xlab=\"x\",ylab=\"density\",main=\"Univariate CDF\")\n  x <-dev.off()\n  \n  filename <- \"pdf_default_gaussian.png\"\npng(filename, width = 1000, height = 1000)\n  tab = read.csv(\"matrix_default.csv\", header=F ,comment.char=\"#\") # read in data in a dataframe\n  x = as.numeric(tab[1,-1]) # assign values of first axis\n  y = as.numeric(tab[-1,1]) # assign values of second axis\n  z = as.matrix(tab[-1,-1]) # cast the remaining data into a  matrix\n  nrz <- nrow(z)\n  ncz <- ncol(z)\n  jet.colors <- colorRampPalette( c(\"red\", \"yellow\") )\n  nbcol <- 20\ncolor <- jet.colors(nbcol)\n  zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] + z[-nrz, -ncz]\nfacetcol <- cut(zfacet, nbcol)\n  persp(x,y,z,col = color[facetcol],zlab=\"density\",main=\"PDF - default bandwidth, gaussian kernel\",phi = 30, theta = -30)\n  t <-dev.off()\n  \n  filename <- \"pdf_optimal_secant_gaussian.png\"\npng(filename, width = 1000, height = 1000)\n  tab = read.csv(\"matrix_optimal.csv\", header=F ,comment.char=\"#\") # read in data in a dataframe\n  x = as.numeric(tab[1,-1]) # assign values of first axis\n  y = as.numeric(tab[-1,1]) # assign values of second axis\n  z = as.matrix(tab[-1,-1]) # cast the remaining data into a  matrix\n  nrz <- nrow(z)\n  ncz <- ncol(z)\n  jet.colors <- colorRampPalette( c(\"red\", \"yellow\") )\n  nbcol <- 20\ncolor <- jet.colors(nbcol)\n  zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] + z[-nrz, -ncz]\nfacetcol <- cut(zfacet, nbcol)\n  persp(x,y,z,col = color[facetcol],zlab=\"density\",main=\"PDF - optimal bandwidth (secant), gaussian kernel\",phi = 30, theta = -30)\n  t <-dev.off()\n  \n  filename <- \"pdf_optimal_bisection_guassian.png\"\npng(filename, width = 1000, height = 1000)\n  tab = read.csv(\"matrix_optimal_safe.csv\", header=F ,comment.char=\"#\") # read in data in a dataframe\n  x = as.numeric(tab[1,-1]) # assign values of first axis\n  y = as.numeric(tab[-1,1]) # assign values of second axis\n  z = as.matrix(tab[-1,-1]) # cast the remaining data into a  matrix\n  nrz <- nrow(z)\n  ncz <- ncol(z)\n  jet.colors <- colorRampPalette( c(\"red\", \"yellow\") )\n  nbcol <- 20\ncolor <- jet.colors(nbcol)\n  zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] + z[-nrz, -ncz]\nfacetcol <- cut(zfacet, nbcol)\n  persp(x,y,z,col = color[facetcol],zlab=\"density\",main=\"PDF - optimal bandwidth (bisection), gaussian kernel\",phi = 30, theta = -30)\n  t <-dev.off()\n  \n  filename <- \"pdf_default_box.png\"\npng(filename, width = 1000, height = 1000)\n  tab = read.csv(\"matrix_default_box.csv\", header=F ,comment.char=\"#\") # read in data in a dataframe\n  x = as.numeric(tab[1,-1]) # assign values of first axis\n  y = as.numeric(tab[-1,1]) # assign values of second axis\n  z = as.matrix(tab[-1,-1]) # cast the remaining data into a  matrix\n  nrz <- nrow(z)\n  ncz <- ncol(z)\n  jet.colors <- colorRampPalette( c(\"red\", \"yellow\") )\n  nbcol <- 20\ncolor <- jet.colors(nbcol)\n  zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] + z[-nrz, -ncz]\nfacetcol <- cut(zfacet, nbcol)\n  persp(x,y,z,col = color[facetcol],zlab=\"density\",main=\"PDF - default bandwidth, box kernel\",phi = 30, theta = -30)\n  t <-dev.off()\n  \n  filename <- \"pdf_default_epanechnikov.png\"\npng(filename, width = 1000, height = 1000)\n  tab = read.csv(\"matrix_default_epa.csv\", header=F ,comment.char=\"#\") # read in data in a dataframe\n  x = as.numeric(tab[1,-1]) # assign values of first axis\n  y = as.numeric(tab[-1,1]) # assign values of second axis\n  z = as.matrix(tab[-1,-1]) # cast the remaining data into a  matrix\n  nrz <- nrow(z)\n  ncz <- ncol(z)\n  jet.colors <- colorRampPalette( c(\"red\", \"yellow\") )\n  nbcol <- 20\ncolor <- jet.colors(nbcol)\n  zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] + z[-nrz, -ncz]\nfacetcol <- cut(zfacet, nbcol)\n  persp(x,y,z,col = color[facetcol],zlab=\"density\",main=\"PDF - default bandwidth, epanechnikov kernel\",phi = 30, theta = -30)\n  t <-dev.off()\n*/\n\n\n\n\n",
    "created" : 1507268269237.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1664058396",
    "id" : "BC744400",
    "lastKnownWriteTime" : 1507747196,
    "last_content_update" : 1507747196,
    "path" : "~/Dropbox (Personal)/Projects/Causal_network/causal_network/Cpp/Real_deal/Scribe/Scribe/src/information_estimator.cpp",
    "project_path" : "src/information_estimator.cpp",
    "properties" : {
    },
    "relative_order" : 12,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "cpp"
}